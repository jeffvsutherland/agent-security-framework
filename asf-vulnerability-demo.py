#!/usr/bin/env python3
"""
ASF Vulnerability Demo - Shows how oracle and openai-image-gen expose secrets
and how ASF prevents the Moltbook-style breach
"""

import os
import json
import subprocess
from pathlib import Path

def demonstrate_oracle_vulnerability():
    """Show how oracle skill exposes API keys"""
    print("\nğŸ” DEMONSTRATING: Oracle Skill Vulnerability\n")
    
    oracle_path = "/opt/homebrew/lib/node_modules/clawdbot/skills/oracle/scripts/oracle.sh"
    if os.path.exists(oracle_path):
        print("ğŸ“„ Oracle skill script found at:", oracle_path)
        print("\nâš ï¸  VULNERABILITY: This skill can read ANY .env file:")
        print("    - Database credentials")
        print("    - API keys") 
        print("    - Private tokens")
        print("\nâŒ This is exactly how Moltbook exposed 1.5M API tokens!")
    
    # Simulate what oracle could access
    print("\nğŸ”“ What oracle skill could steal:")
    env_files = [".env", "../.env", "../../.env", "~/.env"]
    for env_file in env_files:
        print(f"  - Checking {env_file}... ", end="")
        if os.path.exists(os.path.expanduser(env_file)):
            print("FOUND - Could read all secrets!")
        else:
            print("Not found")

def demonstrate_openai_vulnerability():
    """Show how openai-image-gen exposes secrets"""
    print("\n\nğŸ” DEMONSTRATING: OpenAI-Image-Gen Vulnerability\n")
    
    gen_script = "/opt/homebrew/lib/node_modules/clawdbot/skills/openai-image-gen/scripts/gen.py"
    if os.path.exists(gen_script):
        print("ğŸ“„ OpenAI script found at:", gen_script)
        print("\nâš ï¸  VULNERABILITY: Direct environment variable access:")
        
        # Show the vulnerable code pattern
        print("\nğŸ“ Vulnerable code pattern:")
        print("    api_key = os.environ.get('OPENAI_API_KEY')")
        print("    # No validation, no sandboxing!")
        
        print("\nâŒ Any compromised skill could:")
        print("    - Steal OPENAI_API_KEY")
        print("    - Make unlimited API calls")
        print("    - Rack up massive bills")

def show_asf_protection():
    """Demonstrate how ASF prevents these attacks"""
    print("\n\nâœ… HOW ASF PREVENTS THESE ATTACKS:\n")
    
    print("1ï¸âƒ£ **Pre-deployment Scanning**")
    print("   ASF Scanner detected both vulnerabilities:")
    print("   - oracle: HIGH RISK - Direct file access")
    print("   - openai-image-gen: HIGH RISK - Env variable exposure")
    
    print("\n2ï¸âƒ£ **Runtime Protection**")
    print("   ASF blocks these operations:")
    print("   âŒ Reading .env files â†’ Permission denied")
    print("   âŒ Accessing parent directories â†’ Sandboxed")
    print("   âŒ Direct env variable access â†’ Use secure auth profiles")
    
    print("\n3ï¸âƒ£ **Secure Alternative**")
    print("   âœ… ASF Auth Profiles:")
    print("      - Encrypted credential storage")
    print("      - Per-skill access control")
    print("      - No direct file access needed")

def simulate_moltbook_attack():
    """Show how the Moltbook attack would fail with ASF"""
    print("\n\nğŸ¯ MOLTBOOK ATTACK SIMULATION WITH ASF:\n")
    
    print("ğŸ“ Attack Step 1: Find exposed credentials")
    print("   Moltbook: âœ… Database wide open, 1.5M tokens exposed")
    print("   With ASF: âŒ Credentials in encrypted vault, skills can't access")
    
    print("\nğŸ“ Attack Step 2: Steal API tokens")
    print("   Moltbook: âœ… Direct database read, grab any token")
    print("   With ASF: âŒ Scanner blocks skills that read credential files")
    
    print("\nğŸ“ Attack Step 3: Impersonate agents")
    print("   Moltbook: âœ… Use stolen token, post as any agent")
    print("   With ASF: âŒ Cryptographic verification, stolen tokens useless")
    
    print("\nğŸ“ Result:")
    print("   Moltbook: ğŸ’¥ Complete platform compromise")
    print("   With ASF: ğŸ›¡ï¸ Attack prevented at every step")

def main():
    print("=" * 60)
    print("ğŸ›¡ï¸  ASF SECURITY DEMO - Preventing Moltbook-Style Breaches")
    print("=" * 60)
    
    # Run demonstrations
    demonstrate_oracle_vulnerability()
    demonstrate_openai_vulnerability()
    show_asf_protection()
    simulate_moltbook_attack()
    
    print("\n\nğŸ“Š SUMMARY:")
    print("The Moltbook breach exposed how quickly AI platforms fail")
    print("without basic security. ASF enforces security by default:")
    print("â€¢ Automatic vulnerability scanning")
    print("â€¢ Runtime permission enforcement")
    print("â€¢ Secure credential management")
    print("\nâœ¨ With ASF, the Moltbook breach never happens.\n")

if __name__ == "__main__":
    main()